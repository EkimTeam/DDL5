{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:56:53.736551Z",
     "start_time": "2019-11-12T16:56:53.697784Z"
    },
    "id": "WGoorsK6mPZP"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:56:53.930939Z",
     "start_time": "2019-11-12T16:56:53.927524Z"
    },
    "id": "WIcNCt4ZmPZZ"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:56:54.167596Z",
     "start_time": "2019-11-12T16:56:54.164358Z"
    },
    "id": "yiHPlx2wmPZe"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQEb43_PmPZk"
   },
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:56:55.151591Z",
     "start_time": "2019-11-12T16:56:55.148395Z"
    },
    "id": "RAge7EI-mPZl"
   },
   "outputs": [],
   "source": [
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:56:55.451445Z",
     "start_time": "2019-11-12T16:56:55.448384Z"
    },
    "id": "Nd6TznshmPZp"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:56:57.876097Z",
     "start_time": "2019-11-12T16:56:57.866730Z"
    },
    "id": "qb_NW7cVmPZs"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:11:52.832124Z",
     "start_time": "2019-11-12T17:11:52.776322Z"
    },
    "id": "Kw5Kv2i6mPZu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to .\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 26370048/26421880 [00:44<00:00, 461349.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to .\\FashionMNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to .\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "32768it [00:00, 56009.75it/s]            \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to .\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to .\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4422102 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 49152/4422102 [00:00<00:11, 396060.94it/s]\u001b[A\n",
      "  2%|▏         | 81920/4422102 [00:00<00:13, 326121.23it/s]\u001b[A\n",
      "  4%|▍         | 172032/4422102 [00:00<00:10, 393804.77it/s]\u001b[A\n",
      "  5%|▍         | 212992/4422102 [00:00<00:12, 346714.05it/s]\u001b[A\n",
      "  6%|▌         | 262144/4422102 [00:00<00:11, 348846.98it/s]\u001b[A\n",
      "  7%|▋         | 294912/4422102 [00:01<00:15, 273280.29it/s]\u001b[A\n",
      "  8%|▊         | 352256/4422102 [00:01<00:15, 270162.47it/s]\u001b[A\n",
      "  9%|▉         | 409600/4422102 [00:01<00:12, 309159.60it/s]\u001b[A\n",
      " 10%|█         | 450560/4422102 [00:01<00:12, 306719.97it/s]\u001b[A\n",
      " 11%|█▏        | 499712/4422102 [00:01<00:11, 331018.49it/s]\u001b[A\n",
      " 12%|█▏        | 540672/4422102 [00:01<00:12, 310535.25it/s]\u001b[A\n",
      " 13%|█▎        | 589824/4422102 [00:01<00:11, 333807.08it/s]\u001b[A\n",
      " 15%|█▍        | 655360/4422102 [00:02<00:10, 363421.68it/s]\u001b[A\n",
      " 16%|█▌        | 712704/4422102 [00:02<00:11, 324437.42it/s]\u001b[A\n",
      " 17%|█▋        | 770048/4422102 [00:02<00:10, 354958.06it/s]\u001b[A\n",
      " 18%|█▊        | 811008/4422102 [00:02<00:11, 321131.41it/s]\u001b[A\n",
      " 19%|█▉        | 860160/4422102 [00:02<00:10, 334271.48it/s]\u001b[A\n",
      " 20%|██        | 901120/4422102 [00:02<00:11, 312308.05it/s]\u001b[A\n",
      " 22%|██▏       | 958464/4422102 [00:02<00:10, 345261.53it/s]\u001b[A\n",
      " 23%|██▎       | 999424/4422102 [00:03<00:16, 210128.30it/s]\u001b[A\n",
      " 24%|██▍       | 1064960/4422102 [00:03<00:13, 255872.33it/s]\u001b[A\n",
      " 25%|██▌       | 1105920/4422102 [00:03<00:12, 265725.99it/s]\u001b[A\n",
      " 26%|██▌       | 1146880/4422102 [00:03<00:11, 281774.57it/s]\u001b[A\n",
      " 27%|██▋       | 1187840/4422102 [00:03<00:11, 284930.37it/s]\u001b[A\n",
      " 28%|██▊       | 1228800/4422102 [00:04<00:10, 297651.17it/s]\u001b[A\n",
      " 29%|██▊       | 1261568/4422102 [00:04<00:11, 267800.51it/s]\u001b[A\n",
      " 30%|██▉       | 1318912/4422102 [00:04<00:10, 305495.01it/s]\u001b[A\n",
      " 31%|███       | 1359872/4422102 [00:04<00:09, 306957.75it/s]\u001b[A\n",
      " 32%|███▏      | 1400832/4422102 [00:04<00:09, 311466.43it/s]\u001b[A\n",
      " 33%|███▎      | 1441792/4422102 [00:04<00:09, 307607.06it/s]\u001b[A\n",
      " 34%|███▎      | 1490944/4422102 [00:04<00:09, 325187.64it/s]\u001b[A\n",
      " 35%|███▍      | 1531904/4422102 [00:04<00:09, 319077.11it/s]\u001b[A\n",
      " 36%|███▌      | 1589248/4422102 [00:05<00:08, 346035.52it/s]\u001b[A\n",
      " 37%|███▋      | 1630208/4422102 [00:05<00:08, 328878.79it/s]\u001b[A\n",
      " 38%|███▊      | 1695744/4422102 [00:05<00:07, 369652.40it/s]\u001b[A\n",
      " 39%|███▉      | 1736704/4422102 [00:05<00:07, 345166.73it/s]\u001b[A\n",
      " 41%|████      | 1810432/4422102 [00:05<00:06, 391694.30it/s]\u001b[A\n",
      " 42%|████▏     | 1859584/4422102 [00:05<00:06, 380345.99it/s]\u001b[A\n",
      " 44%|████▎     | 1925120/4422102 [00:05<00:05, 421695.67it/s]\u001b[A\n",
      " 45%|████▍     | 1974272/4422102 [00:06<00:06, 391046.10it/s]\u001b[A\n",
      " 46%|████▋     | 2056192/4422102 [00:06<00:05, 444783.57it/s]\u001b[A\n",
      " 48%|████▊     | 2105344/4422102 [00:06<00:05, 405390.31it/s]\u001b[A\n",
      " 49%|████▉     | 2162688/4422102 [00:06<00:05, 420047.12it/s]\u001b[A\n",
      " 50%|█████     | 2211840/4422102 [00:06<00:06, 339188.92it/s]\u001b[A\n",
      " 52%|█████▏    | 2285568/4422102 [00:06<00:06, 351493.59it/s]\u001b[A\n",
      " 53%|█████▎    | 2342912/4422102 [00:06<00:05, 375038.82it/s]\u001b[A\n",
      " 55%|█████▌    | 2441216/4422102 [00:07<00:04, 420317.32it/s]\u001b[A\n",
      " 56%|█████▋    | 2490368/4422102 [00:07<00:05, 351692.12it/s]\u001b[A\n",
      " 58%|█████▊    | 2580480/4422102 [00:07<00:04, 412680.93it/s]\u001b[A\n",
      " 59%|█████▉    | 2629632/4422102 [00:07<00:04, 385593.22it/s]\u001b[A\n",
      " 61%|██████    | 2703360/4422102 [00:07<00:04, 426555.77it/s]\u001b[A\n",
      " 62%|██████▏   | 2760704/4422102 [00:07<00:04, 410213.89it/s]\u001b[A\n",
      " 65%|██████▍   | 2867200/4422102 [00:07<00:03, 488425.21it/s]\u001b[A\n",
      " 66%|██████▋   | 2932736/4422102 [00:08<00:02, 507931.59it/s]\u001b[A\n",
      " 68%|██████▊   | 3022848/4422102 [00:08<00:02, 549080.94it/s]\u001b[A\n",
      " 70%|██████▉   | 3088384/4422102 [00:08<00:02, 523406.90it/s]\u001b[A\n",
      " 71%|███████▏  | 3153920/4422102 [00:08<00:02, 544522.08it/s]\u001b[A\n",
      " 73%|███████▎  | 3219456/4422102 [00:08<00:02, 496707.58it/s]\u001b[A\n",
      " 74%|███████▍  | 3276800/4422102 [00:08<00:02, 482198.71it/s]\u001b[A\n",
      " 75%|███████▌  | 3334144/4422102 [00:08<00:02, 401188.31it/s]\u001b[A\n",
      " 77%|███████▋  | 3391488/4422102 [00:09<00:02, 358950.90it/s]\u001b[A\n",
      " 79%|███████▊  | 3473408/4422102 [00:09<00:02, 410253.44it/s]\u001b[A\n",
      " 80%|███████▉  | 3522560/4422102 [00:09<00:02, 397918.98it/s]\u001b[A\n",
      " 81%|████████  | 3571712/4422102 [00:09<00:02, 398413.02it/s]\u001b[A\n",
      " 82%|████████▏ | 3620864/4422102 [00:09<00:02, 375909.01it/s]\u001b[A\n",
      " 83%|████████▎ | 3686400/4422102 [00:09<00:01, 416969.43it/s]\u001b[A\n",
      " 84%|████████▍ | 3735552/4422102 [00:09<00:01, 391086.66it/s]\u001b[A\n",
      " 86%|████████▌ | 3809280/4422102 [00:10<00:01, 432761.73it/s]\u001b[A\n",
      " 87%|████████▋ | 3858432/4422102 [00:10<00:01, 398603.22it/s]\u001b[A\n",
      " 89%|████████▉ | 3932160/4422102 [00:10<00:01, 356663.58it/s]\u001b[A\n",
      " 91%|█████████ | 4014080/4422102 [00:10<00:00, 410054.74it/s]\u001b[A\n",
      " 92%|█████████▏| 4063232/4422102 [00:10<00:01, 344427.84it/s]\u001b[A\n",
      " 93%|█████████▎| 4120576/4422102 [00:11<00:00, 322079.16it/s]\u001b[A\n",
      " 95%|█████████▌| 4202496/4422102 [00:11<00:00, 372802.49it/s]\u001b[A\n",
      " 96%|█████████▌| 4251648/4422102 [00:11<00:00, 306066.59it/s]\u001b[A\n",
      " 97%|█████████▋| 4292608/4422102 [00:11<00:00, 285481.31it/s]\u001b[A\n",
      " 99%|█████████▊| 4366336/4422102 [00:11<00:00, 337770.09it/s]\u001b[A\n",
      "100%|█████████▉| 4407296/4422102 [00:11<00:00, 322797.36it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to .\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to .\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8192it [00:00, 34133.37it/s]            \u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to .\\FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26427392it [01:00, 461349.38it/s]                              \n",
      "4423680it [00:24, 322797.36it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:58:37.613945Z",
     "start_time": "2019-11-12T16:58:37.608386Z"
    },
    "id": "SKhbDXt_mPZ0",
    "outputId": "1f0ddd67-aa80-4da2-b6c1-45a3c7de33f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LcgNXwOmPZ5"
   },
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:27:44.112235Z",
     "start_time": "2019-11-12T17:27:44.108751Z"
    },
    "id": "5ZF9RBZomPZ-"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:27:43.689461Z",
     "start_time": "2019-11-12T17:27:43.684254Z"
    },
    "id": "V7qWC2EbmPZ5"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 256),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 64),\n",
    "    torch.nn.Dropout(p=0.3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:27:43.957461Z",
     "start_time": "2019-11-12T17:27:43.952900Z"
    },
    "id": "fDqkL214mPZ7"
   },
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-12T17:27:44.267Z"
    },
    "id": "vVqz1hvTmPaA",
    "outputId": "c612dc63-3553-4576-eb01-82e13a11b8d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 8.400, train_loss: 0.521, train_acc: 0.812, test_loss: 0.414, test_acc: 0.846\n",
      "ep: 1, taked: 8.234, train_loss: 0.387, train_acc: 0.861, test_loss: 0.381, test_acc: 0.860\n",
      "ep: 2, taked: 8.199, train_loss: 0.344, train_acc: 0.877, test_loss: 0.391, test_acc: 0.856\n",
      "ep: 3, taked: 8.399, train_loss: 0.312, train_acc: 0.886, test_loss: 0.361, test_acc: 0.875\n",
      "ep: 4, taked: 8.206, train_loss: 0.295, train_acc: 0.893, test_loss: 0.354, test_acc: 0.875\n",
      "ep: 5, taked: 8.523, train_loss: 0.276, train_acc: 0.898, test_loss: 0.385, test_acc: 0.868\n",
      "ep: 6, taked: 9.205, train_loss: 0.258, train_acc: 0.904, test_loss: 0.361, test_acc: 0.872\n",
      "ep: 7, taked: 8.166, train_loss: 0.249, train_acc: 0.908, test_loss: 0.356, test_acc: 0.875\n",
      "ep: 8, taked: 8.068, train_loss: 0.237, train_acc: 0.912, test_loss: 0.349, test_acc: 0.880\n",
      "ep: 9, taked: 8.128, train_loss: 0.226, train_acc: 0.914, test_loss: 0.369, test_acc: 0.875\n",
      "ep: 10, taked: 8.160, train_loss: 0.219, train_acc: 0.918, test_loss: 0.352, test_acc: 0.881\n",
      "ep: 11, taked: 8.152, train_loss: 0.211, train_acc: 0.920, test_loss: 0.410, test_acc: 0.870\n",
      "ep: 12, taked: 8.032, train_loss: 0.200, train_acc: 0.924, test_loss: 0.404, test_acc: 0.873\n",
      "ep: 13, taked: 8.128, train_loss: 0.190, train_acc: 0.926, test_loss: 0.412, test_acc: 0.870\n",
      "ep: 14, taked: 8.009, train_loss: 0.186, train_acc: 0.928, test_loss: 0.402, test_acc: 0.875\n",
      "ep: 15, taked: 8.136, train_loss: 0.178, train_acc: 0.931, test_loss: 0.413, test_acc: 0.877\n",
      "ep: 16, taked: 8.053, train_loss: 0.176, train_acc: 0.932, test_loss: 0.413, test_acc: 0.872\n",
      "ep: 17, taked: 8.219, train_loss: 0.170, train_acc: 0.935, test_loss: 0.453, test_acc: 0.866\n",
      "ep: 18, taked: 8.099, train_loss: 0.161, train_acc: 0.938, test_loss: 0.425, test_acc: 0.874\n",
      "ep: 19, taked: 8.255, train_loss: 0.157, train_acc: 0.939, test_loss: 0.486, test_acc: 0.870\n",
      "ep: 20, taked: 8.055, train_loss: 0.154, train_acc: 0.942, test_loss: 0.418, test_acc: 0.885\n",
      "ep: 21, taked: 8.190, train_loss: 0.147, train_acc: 0.943, test_loss: 0.444, test_acc: 0.881\n",
      "ep: 22, taked: 8.083, train_loss: 0.147, train_acc: 0.942, test_loss: 0.558, test_acc: 0.869\n",
      "ep: 23, taked: 8.171, train_loss: 0.139, train_acc: 0.946, test_loss: 0.453, test_acc: 0.882\n",
      "ep: 24, taked: 8.085, train_loss: 0.135, train_acc: 0.947, test_loss: 0.561, test_acc: 0.871\n",
      "ep: 25, taked: 8.515, train_loss: 0.140, train_acc: 0.945, test_loss: 0.502, test_acc: 0.885\n",
      "ep: 26, taked: 8.331, train_loss: 0.130, train_acc: 0.948, test_loss: 0.490, test_acc: 0.876\n",
      "ep: 27, taked: 8.276, train_loss: 0.128, train_acc: 0.951, test_loss: 0.531, test_acc: 0.877\n",
      "ep: 28, taked: 8.342, train_loss: 0.127, train_acc: 0.950, test_loss: 0.545, test_acc: 0.882\n",
      "ep: 29, taked: 8.336, train_loss: 0.120, train_acc: 0.953, test_loss: 0.563, test_acc: 0.877\n",
      "ep: 30, taked: 8.199, train_loss: 0.122, train_acc: 0.953, test_loss: 0.563, test_acc: 0.887\n",
      "ep: 31, taked: 8.957, train_loss: 0.117, train_acc: 0.954, test_loss: 0.592, test_acc: 0.882\n",
      "ep: 32, taked: 8.985, train_loss: 0.114, train_acc: 0.955, test_loss: 0.574, test_acc: 0.880\n",
      "ep: 33, taked: 8.578, train_loss: 0.111, train_acc: 0.956, test_loss: 0.629, test_acc: 0.875\n",
      "ep: 34, taked: 9.296, train_loss: 0.110, train_acc: 0.958, test_loss: 0.593, test_acc: 0.886\n",
      "ep: 35, taked: 8.349, train_loss: 0.108, train_acc: 0.958, test_loss: 0.637, test_acc: 0.876\n",
      "ep: 36, taked: 8.272, train_loss: 0.102, train_acc: 0.961, test_loss: 0.601, test_acc: 0.886\n",
      "ep: 37, taked: 8.388, train_loss: 0.098, train_acc: 0.961, test_loss: 0.627, test_acc: 0.886\n",
      "ep: 38, taked: 8.540, train_loss: 0.102, train_acc: 0.960, test_loss: 0.640, test_acc: 0.872\n",
      "ep: 39, taked: 8.329, train_loss: 0.100, train_acc: 0.961, test_loss: 0.664, test_acc: 0.883\n",
      "ep: 40, taked: 8.528, train_loss: 0.098, train_acc: 0.962, test_loss: 0.688, test_acc: 0.881\n",
      "ep: 41, taked: 8.642, train_loss: 0.094, train_acc: 0.963, test_loss: 0.685, test_acc: 0.885\n",
      "ep: 42, taked: 8.363, train_loss: 0.094, train_acc: 0.963, test_loss: 0.644, test_acc: 0.888\n",
      "ep: 43, taked: 8.737, train_loss: 0.089, train_acc: 0.966, test_loss: 0.749, test_acc: 0.877\n",
      "ep: 44, taked: 8.463, train_loss: 0.089, train_acc: 0.966, test_loss: 0.768, test_acc: 0.875\n",
      "ep: 45, taked: 8.277, train_loss: 0.088, train_acc: 0.966, test_loss: 0.778, test_acc: 0.882\n",
      "ep: 46, taked: 8.328, train_loss: 0.086, train_acc: 0.967, test_loss: 0.735, test_acc: 0.884\n",
      "ep: 47, taked: 8.775, train_loss: 0.083, train_acc: 0.967, test_loss: 0.789, test_acc: 0.885\n",
      "ep: 48, taked: 9.693, train_loss: 0.084, train_acc: 0.968, test_loss: 0.773, test_acc: 0.886\n",
      "ep: 49, taked: 8.922, train_loss: 0.084, train_acc: 0.968, test_loss: 0.752, test_acc: 0.885\n",
      "ep: 50, taked: 8.574, train_loss: 0.076, train_acc: 0.970, test_loss: 0.774, test_acc: 0.882\n",
      "ep: 51, taked: 8.846, train_loss: 0.077, train_acc: 0.970, test_loss: 0.775, test_acc: 0.882\n",
      "ep: 52, taked: 8.519, train_loss: 0.078, train_acc: 0.970, test_loss: 0.891, test_acc: 0.883\n",
      "ep: 53, taked: 8.637, train_loss: 0.076, train_acc: 0.971, test_loss: 0.801, test_acc: 0.886\n",
      "ep: 54, taked: 9.243, train_loss: 0.078, train_acc: 0.971, test_loss: 0.797, test_acc: 0.879\n",
      "ep: 55, taked: 8.687, train_loss: 0.076, train_acc: 0.971, test_loss: 0.777, test_acc: 0.880\n",
      "ep: 56, taked: 8.540, train_loss: 0.072, train_acc: 0.972, test_loss: 0.792, test_acc: 0.886\n",
      "ep: 57, taked: 8.414, train_loss: 0.074, train_acc: 0.972, test_loss: 0.821, test_acc: 0.876\n",
      "ep: 58, taked: 8.479, train_loss: 0.071, train_acc: 0.973, test_loss: 0.816, test_acc: 0.883\n",
      "ep: 59, taked: 8.311, train_loss: 0.075, train_acc: 0.972, test_loss: 0.835, test_acc: 0.887\n",
      "ep: 60, taked: 8.543, train_loss: 0.067, train_acc: 0.975, test_loss: 0.897, test_acc: 0.879\n",
      "ep: 61, taked: 8.347, train_loss: 0.071, train_acc: 0.973, test_loss: 0.828, test_acc: 0.888\n",
      "ep: 62, taked: 8.500, train_loss: 0.068, train_acc: 0.974, test_loss: 0.812, test_acc: 0.891\n",
      "ep: 63, taked: 8.369, train_loss: 0.062, train_acc: 0.976, test_loss: 0.878, test_acc: 0.882\n",
      "ep: 64, taked: 8.474, train_loss: 0.069, train_acc: 0.974, test_loss: 0.843, test_acc: 0.886\n",
      "ep: 65, taked: 8.727, train_loss: 0.065, train_acc: 0.975, test_loss: 0.980, test_acc: 0.881\n",
      "ep: 66, taked: 8.673, train_loss: 0.070, train_acc: 0.975, test_loss: 0.819, test_acc: 0.884\n",
      "ep: 67, taked: 8.489, train_loss: 0.064, train_acc: 0.976, test_loss: 0.990, test_acc: 0.877\n",
      "ep: 68, taked: 8.433, train_loss: 0.063, train_acc: 0.977, test_loss: 0.940, test_acc: 0.884\n",
      "ep: 69, taked: 8.375, train_loss: 0.057, train_acc: 0.979, test_loss: 0.827, test_acc: 0.883\n",
      "ep: 70, taked: 8.544, train_loss: 0.062, train_acc: 0.978, test_loss: 0.955, test_acc: 0.881\n",
      "ep: 71, taked: 8.769, train_loss: 0.060, train_acc: 0.979, test_loss: 0.988, test_acc: 0.884\n",
      "ep: 72, taked: 8.463, train_loss: 0.059, train_acc: 0.978, test_loss: 0.946, test_acc: 0.883\n",
      "ep: 73, taked: 8.626, train_loss: 0.064, train_acc: 0.976, test_loss: 0.869, test_acc: 0.890\n",
      "ep: 74, taked: 8.730, train_loss: 0.062, train_acc: 0.977, test_loss: 0.981, test_acc: 0.876\n",
      "ep: 75, taked: 8.544, train_loss: 0.059, train_acc: 0.979, test_loss: 1.010, test_acc: 0.882\n",
      "ep: 76, taked: 8.474, train_loss: 0.050, train_acc: 0.981, test_loss: 1.020, test_acc: 0.885\n",
      "ep: 77, taked: 8.593, train_loss: 0.057, train_acc: 0.980, test_loss: 0.952, test_acc: 0.880\n",
      "ep: 78, taked: 8.682, train_loss: 0.055, train_acc: 0.980, test_loss: 1.107, test_acc: 0.879\n",
      "ep: 79, taked: 8.621, train_loss: 0.062, train_acc: 0.979, test_loss: 1.001, test_acc: 0.885\n",
      "ep: 80, taked: 8.513, train_loss: 0.062, train_acc: 0.979, test_loss: 0.975, test_acc: 0.886\n",
      "ep: 81, taked: 8.809, train_loss: 0.064, train_acc: 0.979, test_loss: 0.978, test_acc: 0.888\n",
      "ep: 82, taked: 8.618, train_loss: 0.050, train_acc: 0.982, test_loss: 0.979, test_acc: 0.886\n",
      "ep: 83, taked: 8.588, train_loss: 0.053, train_acc: 0.980, test_loss: 1.041, test_acc: 0.883\n",
      "ep: 84, taked: 8.364, train_loss: 0.056, train_acc: 0.980, test_loss: 0.960, test_acc: 0.884\n",
      "ep: 85, taked: 8.440, train_loss: 0.053, train_acc: 0.980, test_loss: 1.004, test_acc: 0.878\n",
      "ep: 86, taked: 8.522, train_loss: 0.050, train_acc: 0.982, test_loss: 0.996, test_acc: 0.884\n",
      "ep: 87, taked: 8.614, train_loss: 0.054, train_acc: 0.981, test_loss: 1.068, test_acc: 0.878\n",
      "ep: 88, taked: 9.232, train_loss: 0.054, train_acc: 0.981, test_loss: 1.007, test_acc: 0.886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 89, taked: 8.817, train_loss: 0.046, train_acc: 0.982, test_loss: 0.978, test_acc: 0.881\n",
      "ep: 90, taked: 9.186, train_loss: 0.052, train_acc: 0.981, test_loss: 1.066, test_acc: 0.880\n",
      "ep: 91, taked: 9.023, train_loss: 0.051, train_acc: 0.982, test_loss: 0.948, test_acc: 0.888\n",
      "ep: 92, taked: 9.114, train_loss: 0.047, train_acc: 0.983, test_loss: 0.958, test_acc: 0.886\n",
      "ep: 93, taked: 9.333, train_loss: 0.049, train_acc: 0.983, test_loss: 1.116, test_acc: 0.882\n",
      "ep: 94, taked: 8.846, train_loss: 0.050, train_acc: 0.983, test_loss: 1.033, test_acc: 0.884\n",
      "ep: 95, taked: 8.949, train_loss: 0.046, train_acc: 0.984, test_loss: 1.003, test_acc: 0.885\n",
      "ep: 96, taked: 9.029, train_loss: 0.046, train_acc: 0.984, test_loss: 1.015, test_acc: 0.885\n",
      "ep: 97, taked: 9.027, train_loss: 0.049, train_acc: 0.983, test_loss: 1.121, test_acc: 0.885\n",
      "ep: 98, taked: 9.001, train_loss: 0.046, train_acc: 0.984, test_loss: 1.069, test_acc: 0.879\n",
      "ep: 99, taked: 8.953, train_loss: 0.052, train_acc: 0.982, test_loss: 1.063, test_acc: 0.887\n",
      "Wall time: 14min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for ep in range(num_epochs):\n",
    "    train_iters, train_passed  = 0, 0\n",
    "    train_loss, train_acc = 0., 0.\n",
    "    start=time.time()\n",
    "    \n",
    "    model.train()\n",
    "    for X, y in train:\n",
    "        trainer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "        train_loss += l.item()\n",
    "        train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        train_iters += 1\n",
    "        train_passed += len(X)\n",
    "    \n",
    "    test_iters, test_passed  = 0, 0\n",
    "    test_loss, test_acc = 0., 0.\n",
    "    model.eval()\n",
    "    for X, y in test:\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        test_loss += l.item()\n",
    "        test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        test_iters += 1\n",
    "        test_passed += len(X)\n",
    "        \n",
    "    print(\"ep: {}, taked: {:.3f}, train_loss: {:.3f}, train_acc: {:.3f}, test_loss: {:.3f}, test_acc: {:.3f}\".format(\n",
    "        ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
    "        test_loss / test_iters, test_acc / test_passed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bW8thRZnmPaI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Лекция 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
